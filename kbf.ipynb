{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "import kfp.dsl as dsl\n",
    "from kfp.v2.dsl import (\n",
    "    component,\n",
    "    Input,\n",
    "    Output,\n",
    "    Dataset,\n",
    "    Metrics,\n",
    "    pipeline,\n",
    "    Artifact,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_cols(df, cols_to_drop):\n",
    "    df = df.drop(cols_to_drop, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(packages_to_install=['pandas'])\n",
    "def drop_cols(df_artifact: Input[Artifact], cols_to_drop_string: str, output_artifact: Output[Artifact])->None:\n",
    "    import pandas as pd \n",
    "    import json \n",
    "    cols_to_drop = json.loads(cols_to_drop_string)\n",
    "    df = pd.read_csv(df_artifact.path)\n",
    "    df = df.drop(cols_to_drop, axis=1)\n",
    "    df.to_csv(output_artifact.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(packages_to_install=['pandas', 'sklearn'])\n",
    "def preprocessing(df_artifact: Input[Artifact], x_artifact: Output[Artifact], y_artifact: Output[Artifact])->None:\n",
    "    import pandas as pd \n",
    "    from sklearn.preprocessing import LabelEncoder, OneHotEncoder, RobustScaler\n",
    "    le = LabelEncoder()\n",
    "    ohe = OneHotEncoder()\n",
    "    scaler = RobustScaler()\n",
    "\n",
    "    df = pd.read_csv(df_artifact.path)\n",
    "\n",
    "    def drop_cols(df, cols_to_drop):\n",
    "        df = df.drop(cols_to_drop, axis=1)\n",
    "        return df\n",
    "\n",
    "    def encode_sex(df):\n",
    "        df['Male'] = le.fit_transform(df.Sex)\n",
    "        df = df.drop(['Sex'], axis=1)\n",
    "        return df\n",
    "\n",
    "    def imputation_by_group(df, column_to_impute, columns_to_group_by):\n",
    "        \"\"\"Impute the column_to_impute by taking the median group on columns_to_group_by\"\"\"\n",
    "        df[column_to_impute] = df.groupby(columns_to_group_by)[column_to_impute].apply(lambda x: x.fillna(x.median()))\n",
    "        return df \n",
    "\n",
    "    def fill_categorical_most_common(df, column_to_fill):\n",
    "        \"\"\"Fill nulls in categorical column_to_fill with the most common variable\"\"\"\n",
    "        most_common = df[column_to_fill].mode()[0]\n",
    "        df[column_to_fill].fillna(most_common)\n",
    "        return df\n",
    "\n",
    "    def one_hot_encoding(df, col_to_encode):\n",
    "        \"\"\"One hot encodes categorical variable col_to_encode and drops the least common column\"\"\"\n",
    "        result = ohe.fit_transform(df[col_to_encode].values.reshape(-1,1)).toarray()\n",
    "\n",
    "        feature_names = ohe.get_feature_names().tolist()\n",
    "        df[feature_names] = pd.DataFrame(result, index=df.index)\n",
    "\n",
    "        least_common = df[col_to_encode].value_counts().index[-1]\n",
    "        col_to_drop = 'x0_'+least_common\n",
    "        df = df.drop([col_to_encode, col_to_drop], axis=1)\n",
    "        return df \n",
    "\n",
    "    def robust_scaling(df, col_to_scale):\n",
    "        df[col_to_scale] = scaler.fit_transform(train_df[col_to_scale].values.reshape(-1,1))\n",
    "        return df\n",
    "\n",
    "    def binary_binning(df, col_to_bin):\n",
    "        \"\"\"Takes col_to_bin and creates binary count for 0 or 1+\"\"\"\n",
    "        correction = lambda x: 1 if x != 0 else 0\n",
    "        df[col_to_bin] = df[col_to_bin].apply(correction)\n",
    "        return df\n",
    "\n",
    "    non_informative_cols = ['PassengerId', 'Name', 'Ticket']\n",
    "    df = drop_cols(df, non_informative_cols)\n",
    "\n",
    "    mostly_null_cols = ['Cabin']\n",
    "    df = drop_cols(df, mostly_null_cols)\n",
    "\n",
    "    df = encode_sex(df)\n",
    "\n",
    "    df = imputation_by_group(df, 'Age', ['Pclass', 'Male'])\n",
    "    df = imputation_by_group(df, 'Fare', 'Pclass')\n",
    "\n",
    "    df = fill_categorical_most_common(df, 'Embarked')\n",
    "\n",
    "    df = one_hot_encoding(df, 'Embarked')\n",
    "\n",
    "    df = robust_scaling(df, 'Age')\n",
    "    df = robust_scaling(df, 'Fare')\n",
    "\n",
    "    df = binary_binning(df, 'SibSp')\n",
    "    df = binary_binning(df, 'Parch')\n",
    "\n",
    "    y = df.Survived\n",
    "    x = df.drop('Survived', axis=1)\n",
    "\n",
    "    x.to_csv(x_artifact.path)\n",
    "    y.to_csv(y_artifact.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(packages_to_install=['pandas', 'sklearn'])\n",
    "def train_model(x_artifact: Input[Artifact], y_artifact: Input[Artifact], model_artifact: Output[Artifact])->None:\n",
    "    import pandas as pd \n",
    "    import pickle\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    logreg = LogisticRegression()\n",
    "\n",
    "    x = pd.read_csv(x_artifact.path)\n",
    "    y = pd.read_csv(y_artifact.path)\n",
    "\n",
    "    logreg.fit(x,y)\n",
    "\n",
    "    pickle.dump(logreg, open(model_artifact.path, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(packages_to_install=['pandas', 'sklearn'])\n",
    "def predict(model_artifact: Input[Artifact], x_test_artifact: Input[Artifact], y_pred_artifact: Output[Artifact])->None:\n",
    "    import pandas as pd \n",
    "    import pickle \n",
    "\n",
    "    model = pickle.load(open(model_artifact.path, 'rb'))\n",
    "\n",
    "    x_test = pd.read_csv(x_test_artifact.path)\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred.to_csv(y_pred_artifact.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(packages_to_install=['pandas', 'sklearn'])\n",
    "def evaluate(y_test_artifact: Input[Artifact], y_pred_artifact: Input[Artifact])->float:\n",
    "    import pandas as pd\n",
    "    import sklearn \n",
    "    from sklearn.metrics import accuracy_score\n",
    "\n",
    "    y_test = pd.read_csv(y_test_artifact.path)\n",
    "    y_pred = pd.read_csv(y_pred_artifact.path)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(packages_to_install = ['google-cloud-storage']\n",
    ")\n",
    "def download_gcs_file(\n",
    "project : str,\n",
    "bucket : str,\n",
    "filepath : str,\n",
    "output_file : Output[Artifact]\n",
    ") -> None:\n",
    "'''Downloads a file from GCS to a KFP Artifact component'''\n",
    "from google.cloud import storage\n",
    "\n",
    "client = storage.Client(project = project)\n",
    "bucket = client.get_bucket(bucket)\n",
    "blob = bucket.blob(filepath)\n",
    "\n",
    "blob.download_to_filename(output_file.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline('titanic_pipeline')\n",
    "def create_pipleine(cols_to_drop_string: str):\n",
    "    download_gcs_file_op = download_gcs_file(project_string, bukcet_string, filepath_string)\n",
    "\n",
    "    drop_cols_op = drop_cols(download_gcs_file_op.output, cols_to_drop_string)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline(name='titanic_pipleine', description='dummy pipeline on titanic dataset')\n",
    "def build_pipeline():\n",
    "    preprocessing_op = preprocessing(df)\n",
    "    train_model_op = train_model(preprocessing_op.output)\n",
    "    predict_op = predict(train_model_op.output, x_test)\n",
    "    evaluate_op = evaluate(y_test, predict_op.output)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9fec3ab36716fe125c1a0073683c6433cb45ee410fe515abe8040210eb6e3016"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
